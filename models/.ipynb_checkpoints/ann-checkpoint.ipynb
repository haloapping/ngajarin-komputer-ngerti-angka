{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b59c2b5-cf4c-45f8-a6a7-524d68324207",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49da77f8-5345-4d52-b9c7-4981d15e2d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "\n",
    "from datetime import datetime\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms, datasets\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1d117c-bf7a-4da0-bebc-4e95df1ba756",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c37d7131-05dc-491e-9e77-5fc7dca3604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: (x / 255) - 0.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9edb694d-a778-477b-ab67-62d63a3d2fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"../datasets/train.csv\")\n",
    "test_dataset = pd.read_csv(\"../datasets/test.csv\")\n",
    "\n",
    "X_train = transform(torch.FloatTensor(train_dataset.loc[:, train_dataset.columns != 'label'].to_numpy()))\n",
    "y_train = torch.LongTensor(train_dataset.label.to_numpy())\n",
    "\n",
    "X_test = transform(torch.FloatTensor(test_dataset.loc[:, test_dataset.columns != 'label'].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f24e7b56-e955-4e63-8feb-f167419e0bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([42000, 784]), torch.Size([42000]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c481f5-deb6-4c81-8f0c-2b8b714438e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28000, 784])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57016bf3-0c57-4254-aea4-dcf20f810ba7",
   "metadata": {},
   "source": [
    "# Tensor Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa12b80f-347c-4bb9-82b4-b0e03a32967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e90ebfa-1b99-45f8-b2f6-5f4a44c1ddca",
   "metadata": {},
   "source": [
    "# Dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89617e3b-e478-4c76-938b-fabd414b5d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42191d70-bf55-4093-b89a-d2000ceadb17",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d83d4476-bbc3-470d-a36e-d17f3ab18264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (feature): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=1024, bias=True)\n",
       "    (1): Dropout(p=0.6, inplace=False)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  )\n",
       "  (output): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, width_img, height_img):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Linear(in_features=width_img * height_img, out_features=1024),\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=2048),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=2048, out_features=10)\n",
    "        )\n",
    "        self.output = nn.Softmax(dim=1)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x_feature = self.feature(x)\n",
    "        x_output = self.output(x_feature)\n",
    "        \n",
    "        return x_output\n",
    "    \n",
    "    def get_feature(self, x):        \n",
    "        return self.feature[0:4](x)\n",
    "\n",
    "def init_wb_kaiming_uniform(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(layer.weight.data, a=0, mode=\"fan_in\", nonlinearity=\"leaky_relu\")\n",
    "        nn.init.kaiming_uniform_(layer.bias.data.reshape(layer.bias.data.shape[0], 1), a=0, mode=\"fan_in\", nonlinearity=\"leaky_relu\")    \n",
    "\n",
    "model = CustomModel(28, 28).to(device)\n",
    "model.apply(init_wb_kaiming_uniform)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36100060-b23a-485c-bc77-303bf510bc28",
   "metadata": {},
   "source": [
    "# Eval Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ae54800-8238-42bc-834c-60c738d4e394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Accuracy(), Accuracy())"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metric_train = Accuracy().to(device)\n",
    "eval_metric_test = Accuracy().to(device)\n",
    "eval_metric_train, eval_metric_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9416b728-12f9-40ed-aa5d-304b628cb6aa",
   "metadata": {},
   "source": [
    "# Loss Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f737e9ec-3951-4b0a-8ac8-08746f69229a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_metric = nn.CrossEntropyLoss().to(device)\n",
    "loss_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fdd1ef-5d19-456b-9986-7e2bcc2c5b6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e84086b9-f4e6-4227-b849-f98a612e9b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 6.25e-05\n",
       "    maximize: False\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=6.25e-05)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9fda2f-19a5-49a6-9672-acc2cc95fafa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d6f0a29-738f-4d54-8e8d-28b9eff105ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(dataloader, model, loss_metric, eval_metric, optimizer, show_metric_every):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for batch, (data, actual_labels) in enumerate(train_dataloader, 1):\n",
    "        data = data.to(device)\n",
    "        actual_labels = actual_labels.to(device)\n",
    "        \n",
    "        # Forward Propagation\n",
    "        pred_labels = model(data)\n",
    "        loss = loss_metric(pred_labels, actual_labels)\n",
    "        evaluate = eval_metric(pred_labels, actual_labels)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        if batch % show_metric_every == 0 or batch == len(train_dataloader):\n",
    "            print(f\"Batch {batch} >> loss: {loss:.3f} | acc: {evaluate:.3f}\")\n",
    "        \n",
    "        # Backward Propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    mean_loss = torch.mean(torch.tensor(losses))\n",
    "    mean_metric = eval_metric.compute()\n",
    "    \n",
    "    return mean_loss, mean_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d85c4d2-a25b-4aa5-bb75-a672ad0a0169",
   "metadata": {},
   "source": [
    "# Testing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cba1ad4a-3ab6-4a80-b805-96c3a479876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_step(dataloader, model, loss_metric, eval_metric, optimizer, show_metric_every):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for batch, (data, actual_labels) in enumerate(test_dataloader, 1):\n",
    "        data = data.to(device)\n",
    "        actual_labels = actual_labels.to(device)\n",
    "        \n",
    "        # Forward Propagation\n",
    "        pred_labels = model(data)\n",
    "        loss = loss_metric(pred_labels, actual_labels)\n",
    "        evaluate = eval_metric(pred_labels, actual_labels)\n",
    "        losses.append(loss_metric)\n",
    "        \n",
    "        if batch % show_metric_every == 0 or batch == len(test_dataloader):\n",
    "            print(f\"Batch {batch} >> loss: {loss:.3f} | acc: {evaluate:.3f}\")\n",
    "\n",
    "    mean_loss = torch.mean(torch.tensor(losses))\n",
    "    mean_metric = eval_metric.compute()\n",
    "    \n",
    "    return mean_loss, mean_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c3e00f-d166-415b-8a32-aa61af2245c1",
   "metadata": {},
   "source": [
    "# Fitting Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcda9b06-b35b-4f5c-bbc0-b43bf02b56a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "========================================\n",
      "Train\n",
      "Batch 20 >> loss: 1.654 | acc: 0.812\n",
      "Batch 40 >> loss: 1.633 | acc: 0.828\n",
      "Batch 60 >> loss: 1.618 | acc: 0.859\n",
      "Batch 80 >> loss: 1.694 | acc: 0.766\n",
      "Batch 100 >> loss: 1.680 | acc: 0.812\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "now = datetime.now(tz=pytz.timezone(\"Asia/Makassar\"))\n",
    "now = now.strftime(\"%m_%d_%Y-%H_%M_%S\")\n",
    "os.makedirs(f\"../callbacks/{now}/epochs\", exist_ok=True)\n",
    "\n",
    "def fitting_step(n_epoch, n_penalty, train_dataloader, model, loss_metric, eval_metric_train, eval_metric_test, optimizer, device, show_metric_every):\n",
    "    epoch = 1\n",
    "    n_current_penalty = 0\n",
    "    train_losses, train_metrics = [], []\n",
    "    # test_losses, test_metrics = [], []\n",
    "    \n",
    "    while True:\n",
    "        print(f\"EPOCH {epoch}\")\n",
    "        print(\"=\" * 40)\n",
    "        print(f\"Train\")\n",
    "        train_loss, train_metric = training_step(train_dataloader, model, loss_metric, eval_metric_train, optimizer, show_metric_every)\n",
    "        train_losses.append(train_loss.to(\"cpu\"))\n",
    "        train_metrics.append(train_metric.to(\"cpu\"))\n",
    "        print(f\"Average train loss : {train_loss:.3f}\")\n",
    "        print(f\"Average train acc  : {train_metric:.3f}\\n\")\n",
    "        \n",
    "        # print(f\"Test\")\n",
    "        # test_loss, test_metric = testing_step(test_dataloader, model, losseval_metric, eval_metric_test, optimizer)\n",
    "        # test_losses.append(test_loss)\n",
    "        # test_metrics.append(test_metric)\n",
    "        # print(f\"Average test loss : {test_loss:.3f}\")\n",
    "        # print(f\"Average test acc  : {test_metric:.3f}\\n\")\n",
    "\n",
    "        if epoch != 1:\n",
    "            if train_losses[-1] > train_losses[-2]:\n",
    "                n_current_penalty += 1\n",
    "                print(f\"Not improve! Number of penalty = {n_current_penalty}/{n_penalty}! 😔\")\n",
    "            elif train_losses[-1] < train_losses[-2] and n_current_penalty != 0:\n",
    "                n_current_penalty -= 1\n",
    "                print(f\"Improve! 😄\")\n",
    "            else:\n",
    "                print(f\"Improve! 😄\")\n",
    "\n",
    "            if n_current_penalty == n_penalty:\n",
    "                print(f\"Number of penalty = {n_current_penalty}/{n_penalty}!, training stopped!\")\n",
    "                break\n",
    "                \n",
    "            # if train_losses[-1] < test_losses[-1]:\n",
    "            #     print(\"Model overfit! Training stopped.\")\n",
    "            #     break\n",
    "        print(\"=\" * 40 + \"\\n\")\n",
    "        torch.save(model.state_dict(), f\"../callbacks/{now}/epochs/{str(epoch).zfill(4)}.pth\")\n",
    "        epoch += 1\n",
    "        eval_metric_train.reset()\n",
    "        eval_metric_test.reset()\n",
    "    torch.save(model.state_dict(), f\"../callbacks/{now}/epochs/{str(epoch).zfill(4)}.pth\")\n",
    "    print(\"Done!\")\n",
    "    return train_losses, train_metrics\n",
    "\n",
    "train_losses, train_metrics = fitting_step(2, 3, train_dataloader, model, loss_metric, eval_metric_train, eval_metric_test, optimizer, device, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974303cf-1595-48c6-a3d8-e761cda4b60c",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cb8b6d-e042-431a-9fb4-f0ec5e41e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"../pretrained_models/{now}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b5e5c0-68f1-49e5-b21c-3a504cfa224e",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325d64ff-6f38-4898-82f7-aeaa1a9f3090",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, tight_layout=True, figsize=(10, 10))\n",
    "\n",
    "ax[0][0].set_title(\"Train Accuracy\")\n",
    "ax[0][0].plot(train_metrics, label=\"Accuracy\")\n",
    "ax[0][0].set_xlabel(\"Epoch\")\n",
    "ax[0][0].set_ylabel(\"Score\")\n",
    "ax[0][0].grid()\n",
    "ax[0][0].legend()\n",
    "\n",
    "ax[0][1].set_title(\"Train Loss\")\n",
    "ax[0][1].plot(train_losses, label=\"Loss\")\n",
    "ax[0][1].set_xlabel(\"Epoch\")\n",
    "ax[0][1].set_ylabel(\"Score\")\n",
    "ax[0][1].grid()\n",
    "ax[0][1].legend();\n",
    "\n",
    "# ax[1][0].set_title(\"Train and Test Loss\")\n",
    "# ax[1][0].plot(train_losses, label=\"Train\")\n",
    "# ax[1][0].plot(test_losses, label=\"Test\")\n",
    "# ax[1][0].set_xlabel(\"Epoch\")\n",
    "# ax[1][0].set_ylabel(\"Score\")\n",
    "# ax[1][0].grid()\n",
    "# ax[1][0].legend()\n",
    "\n",
    "# ax[1][1].set_title(\"Train and Test Accuracy\")\n",
    "# ax[1][1].plot(train_metrics, label=\"Train\")\n",
    "# ax[1][1].plot(test_metrics, label=\"Test\")\n",
    "# ax[1][1].set_xlabel(\"Epoch\")\n",
    "# ax[1][1].set_ylabel(\"Score\")\n",
    "# ax[1][1].grid()\n",
    "# ax[1][1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5befbcf9-7b84-4d2e-8331-83e98376ee31",
   "metadata": {},
   "source": [
    "## X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c36d00-70fd-46c2-998e-81f7e0bda130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(f\"../callbacks/{now}/images\", exist_ok=True)\n",
    "# model.eval()\n",
    "# n_image = 900\n",
    "# idx_start = np.random.randint(0, len(X_test) - 1)\n",
    "# features = X_train[idx_start:idx_start+n_image].to(device)\n",
    "# actual_labels = y_train[idx_start:idx_start+n_image].to(device)\n",
    "# pred_labels = model(features).argmax(1)\n",
    "\n",
    "# plt.figure(figsize=(n_image**0.5, n_image**0.5), tight_layout=True)\n",
    "# for i in range(1, n_image + 1):\n",
    "#     plt.subplot(int(n_image**0.5), int(n_image**0.5), i)\n",
    "#     color_text = \"green\" if pred_labels[i-1] == actual_labels[i-1] else \"red\"\n",
    "#     plt.title(f\"Pred: {pred_labels[i-1]} | Actual {actual_labels[i-1]}\", size=7, color=color_text)\n",
    "#     plt.imshow(features[i-1].reshape((28, 28)).to(\"cpu\"), cmap=plt.cm.gray)\n",
    "#     plt.axis(\"off\")\n",
    "# plt.savefig(f\"../callbacks/{now}/images/X_train_prediction.jpeg\", dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1a1753-d993-422e-99c4-cccacaff83b6",
   "metadata": {},
   "source": [
    "## X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3fc974-e8cd-43ac-beaf-04c36244b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(f\"../callbacks/{now}/images\", exist_ok=True)\n",
    "# model.eval()\n",
    "# n_image = 900\n",
    "# idx_start = np.random.randint(0, len(X_test) - 1)\n",
    "# features = X_test[idx_start:idx_start+n_image].to(device)\n",
    "# pred_labels = model(features).argmax(1)\n",
    "\n",
    "# plt.figure(figsize=(n_image**0.5, n_image**0.5), tight_layout=True)\n",
    "# for i in range(1, n_image + 1):\n",
    "#     plt.subplot(int(n_image**0.5), int(n_image**0.5), i)\n",
    "#     plt.title(f\"Pred: {pred_labels[i-1]}\", color=\"black\")\n",
    "#     plt.imshow(features[i-1].reshape((28, 28)).to(\"cpu\"), cmap=plt.cm.gray)\n",
    "#     plt.axis(\"off\")\n",
    "# plt.savefig(f\"../callbacks/{now}/images/X_test_prediction.jpeg\", dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afad396-69a4-47a1-883a-2f4a387b015a",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e38560-76d6-4ea9-9746-67281fa0c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_labels = model(X_test.to(device)).argmax(1)\n",
    "# submission_df = pd.DataFrame({\n",
    "#     \"ImageId\": np.arange(1, 28001),\n",
    "#     \"Label\": pred_labels.to(\"cpu\")\n",
    "# })\n",
    "\n",
    "# submission_df.to_csv(f\"../submissions/{now}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5f8489-2ef2-42da-b1ca-4f1dbf5b59f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f\"../callbacks/{now}/epochs/0074.pth\"))\n",
    "model.eval()\n",
    "pred_labels = model(X_test.to(device)).argmax(1)\n",
    "submission_df = pd.DataFrame({\n",
    "    \"ImageId\": np.arange(1, len(pred_labels) + 1),\n",
    "    \"Label\": pred_labels.to(\"cpu\")\n",
    "})\n",
    "\n",
    "submission_df.to_csv(f\"../submissions/{now}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f7ecd-d1f8-467f-99ec-7ea78fdc7508",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([params.numel() for params in rnn.parameters() if params.requires_grad == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ede03cf-4e60-4ec7-9cae-9ccd6f08edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, params in model.named_parameters():\n",
    "    if params.requires_grad:\n",
    "        print(f\"{name}: {params.numel()} params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a796ec-0d96-40c7-91ab-85e4ad02b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, params in rnn.named_parameters():\n",
    "    \n",
    "    if params.requires_grad:\n",
    "        print(f\"{type(name)}: {params.numel()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be45e2ad-c86d-4f60-bcbb-0bfa5f0ff717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
